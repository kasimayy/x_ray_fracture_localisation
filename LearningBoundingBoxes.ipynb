{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages',\n",
       " '',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python27.zip',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/plat-linux2',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/lib-tk',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/lib-old',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/lib-dynload',\n",
       " '/homes/ag6516/.local/lib/python2.7/site-packages',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/homes/ag6516/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set local python and nltk paths\n",
    "import sys\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages')\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg')\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/IPython/extensions')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "from random import randint\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir = ('/vol/medic02/users/ag6516/x_ray_fracture_localisation/')\n",
    "# dir = ('/Users/Aydan/PhD/x_ray_fracture_localisation/')\n",
    "df = pd.read_csv(dir + 'cleaned_reports_edited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n"
     ]
    }
   ],
   "source": [
    "exam_ids = []\n",
    "for folder in os.listdir(dir+'data/Images'):\n",
    "    exam_ids.append(str(folder))\n",
    "    \n",
    "print len(exam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HBL': 12, 'WBAP': 25, 'L': 90, 'AP': 61, 'S': 26, 'WBL': 17}\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "sample_images = []\n",
    "views = {}\n",
    "for eid in exam_ids:\n",
    "    for image in os.listdir(dir + 'data/Images/' + str(eid)):\n",
    "        if image.endswith('.jpg'):\n",
    "            item = {}\n",
    "            imid = os.path.splitext(image)[0] \n",
    "            item['exam id'] = eid\n",
    "            item['impath'] = eid + '/' + image\n",
    "            if '_' in image and os.path.exists(dir + 'data/Images/' + str(eid) + '/' + 'SSImages_BB' + '/' + 'ss_' + image):             \n",
    "                leg = imid.split('_')[-1]\n",
    "                \n",
    "                if leg != 'B':\n",
    "                    view = imid.split('_')[-2]\n",
    "\n",
    "                    item['imid'] = imid #.split('_')[0]\n",
    "                    item['leg'] = leg\n",
    "                    item['view'] = view\n",
    "                    if view not in views.keys():\n",
    "                        views[view] = 0\n",
    "                    views[view] = views[view] + 1\n",
    "\n",
    "                    f_ = open(dir + 'data/Images/' + str(eid) + '/' + 'SSImages_BB' + '/'  + image + '.txt', 'r')\n",
    "                    item['bbox'] = f_.readlines()[1].rstrip('\\n').split(' ')\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "            sample_images.append(item)\n",
    "print views\n",
    "print len(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train, test = model_selection.train_test_split(sample_images, train_size=0.8, random_state=42)\n",
    "\n",
    "print len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crop and pad images, adjust bounding box coordinates\n",
    "\n",
    "def crop_image(im, bbox):\n",
    "    # Central crop to 256x256\n",
    "    im = np.array(im)\n",
    "    h, w, _ = im.shape\n",
    "    #print 'Before: ',h,w\n",
    "    if h > 256 and w > 256:\n",
    "        im = im[h//2-128:h//2+128, w//2-128:w//2+128]\n",
    "        bbox[0] = bbox[0] - (w-256)//2\n",
    "        bbox[1] = bbox[1] - (h-256)//2\n",
    "        bbox[2] = bbox[2] - (w-256)//2\n",
    "        bbox[3] = bbox[3] - (h-256)//2\n",
    "    elif h > 256 and w < 256:\n",
    "        #print 'width<256 ', p\n",
    "        p = abs(w-256)//2\n",
    "        im = im[h//2-128:h//2+128, :]\n",
    "        if abs(w-256)%2==0:\n",
    "            im = np.pad(im, ((0,0), (p,p), (0,0)), 'maximum')\n",
    "        else:\n",
    "            im = np.pad(im, ((0,0), (p,p+1), (0,0)), 'maximum')\n",
    "        bbox[0] = bbox[0] + p\n",
    "        bbox[1] = bbox[1] - (h-256)//2\n",
    "        bbox[2] = bbox[2] + p\n",
    "        bbox[3] = bbox[3] - (h-256)//2\n",
    "    elif h < 256 and w > 256:\n",
    "        p = abs(h-256)//2\n",
    "        #print 'height<256 ', p\n",
    "        im = im[:,  w//2-128:w//2+128]\n",
    "        if abs(h-256)%2==0:\n",
    "            im = np.pad(im, ((p,p), (0,0), (0,0)), 'maximum')\n",
    "        else:\n",
    "            im = np.pad(im, ((p,p+1), (0,0), (0,0)), 'maximum')\n",
    "        bbox[0] = bbox[0] - (w-256)//2\n",
    "        bbox[1] = bbox[1] + p\n",
    "        bbox[2] = bbox[2] - (w-256)//2\n",
    "        bbox[3] = bbox[3] + p\n",
    "    elif h < 256 and w < 256:\n",
    "        ph = abs(h-256)//2\n",
    "        pw = abs(w-256)//2\n",
    "        print pw, ph\n",
    "        im = np.pad(im, ((ph,ph), (pw,pw), (0,0)), 'maximum')\n",
    "        bbox[0] = bbox[0] + pw\n",
    "        bbox[1] = bbox[1] + ph\n",
    "        bbox[2] = bbox[2] + pw\n",
    "        bbox[3] = bbox[3] + ph\n",
    "    \n",
    "    # if bounding boxes fall out of range, set to max height/width\n",
    "    if bbox[0] < 0:\n",
    "        bbox[0] = 0\n",
    "    if bbox[1] < 0:\n",
    "        bbox[1] = 0\n",
    "    if bbox[2] > 256:\n",
    "        bbox[2] = 256\n",
    "    if bbox[3] > 256:\n",
    "        bbox[3] = 256\n",
    "    #rawim = np.copy(im).astype('uint8')\n",
    "    h, w, _ = im.shape\n",
    "    #print 'After: ', h,w\n",
    "    return im, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_batch(data, batch_size=100, display_images = False):\n",
    "    batch = random.sample(data, batch_size)\n",
    "    images = []\n",
    "    bboxes = []\n",
    "    for i in batch:\n",
    "        if display_images:\n",
    "            plt.figure()\n",
    "        \n",
    "        path = dir + 'data/Images/' + str(i['exam id']) + '/' + 'SSImages_BB' + '/'  + 'ss_' + i['imid'] + '.jpg'\n",
    "        im = plt.imread(path)\n",
    "        bbox = np.asarray(i['bbox'], dtype=int)\n",
    "        if display_images:\n",
    "        #print 'Original: ', im.shape, 'Original bbox: ', i['bbox']\n",
    "            plt.subplot(1,2,1).set_title('Org. bbox: ' + str(bbox))\n",
    "            plt.subplot(1,2,1).imshow(im)\n",
    "            rect1 = patches.Rectangle((bbox[0],bbox[1]),abs(bbox[2]-bbox[0]),abs(bbox[3]-bbox[1]),linewidth=1,edgecolor='r',facecolor='none')\n",
    "            plt.subplot(1,2,1).add_patch(rect1)\n",
    "        \n",
    "        im, bbox = crop_image(im, bbox)\n",
    "        if display_images:\n",
    "        #print 'Cropped: ', im.shape, 'Adjusted bbox: ', bbox\n",
    "            plt.subplot(1,2,2).set_title('Adj. bbox: ' + str(bbox))\n",
    "            plt.subplot(1,2,2).imshow(im)\n",
    "            rect2 = patches.Rectangle((bbox[0],bbox[1]),abs(bbox[2]-bbox[0]),abs(bbox[3]-bbox[1]),linewidth=1,edgecolor='r',facecolor='none')\n",
    "            plt.subplot(1,2,2).add_patch(rect2)\n",
    "        \n",
    "        images.append(im)\n",
    "        bboxes.append(bbox)\n",
    "\n",
    "    return np.array(images), np.array(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "images, bboxes = next_batch(train, batch_size=184)\n",
    "print images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 256*256*3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "\n",
    "W = tf.Variable(tf.zeros([256*256*3,4]))\n",
    "b = tf.Variable(tf.zeros([4]))\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "y = tf.matmul(x,W) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.losses.mean_squared_error(y_, y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27476e+18\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b487cd82e26f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6c8649009280>\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(data, batch_size, display_images)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data/Images/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exam id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'SSImages_BB'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'ss_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisplay_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m             raise ValueError('Only know how to handle extensions: %s; '\n",
      "\u001b[0;32m/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mpilread\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[0mhandlers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_png\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_png\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mpil_to_array\u001b[0;34m(pilImage)\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;31m# return MxNx3 RGB array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilImage\u001b[0m  \u001b[0;31m# no need to RGB images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(im, dtype)\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;31m# Pillow wants us to use \"tobytes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tobytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m             \u001b[0mx_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m             \u001b[0mx_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/PIL/ImageFile.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BS = 20\n",
    "print_y = tf.Print(y,[y])\n",
    "\n",
    "for i in range(1000):\n",
    "    images, bboxes = next_batch(train, batch_size=20)\n",
    "    images = np.reshape(images, [BS, 256*256*3])\n",
    "    train_step.run(feed_dict={x: images, y_: bboxes})\n",
    "    if i%100==0:\n",
    "        print loss.eval(feed_dict={x: images, y_: bboxes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "# Input Layer\n",
    "input_layer = tf.placeholder(tf.float32, [None, 256, 256, 3])\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=32,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# Pooling Layer #1\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Convolutional Layer #2 and Pooling Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Dense Layer\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=dense, rate=0.4, training=tf.estimator.ModeKeys.TRAIN == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "# Output Layer\n",
    "output = tf.layers.dense(inputs=dropout, units=4)\n",
    "\n",
    "# Loss\n",
    "loss = tf.reduce_mean(tf.losses.mean_squared_error(bboxes, output))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "      for i in range(20000):\n",
    "        images, bboxes = next_batch(train, batch_size=10)\n",
    "        if i % 100 == 0:\n",
    "            train_loss = loss.eval(feed_dict={\n",
    "                x: images, y_: bboxes})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlow]",
   "language": "python",
   "name": "conda-env-TensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
