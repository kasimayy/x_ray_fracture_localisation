{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages',\n",
       " '',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python27.zip',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/plat-linux2',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/lib-tk',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/lib-old',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/lib-dynload',\n",
       " '/homes/ag6516/.local/lib/python2.7/site-packages',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages',\n",
       " '/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/homes/ag6516/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set local python and nltk paths\n",
    "import sys\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages')\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg')\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/IPython/extensions')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "from random import randint\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir = ('/vol/medic02/users/ag6516/x_ray_fracture_localisation/')\n",
    "# dir = ('/Users/Aydan/PhD/x_ray_fracture_localisation/')\n",
    "df = pd.read_csv(dir + 'cleaned_reports_edited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n"
     ]
    }
   ],
   "source": [
    "exam_ids = []\n",
    "for folder in os.listdir(dir+'data/Images'):\n",
    "    exam_ids.append(str(folder))\n",
    "    \n",
    "print len(exam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HBL': 12, 'WBAP': 25, 'L': 90, 'AP': 61, 'S': 26, 'WBL': 17}\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "sample_images = []\n",
    "views = {}\n",
    "for eid in exam_ids:\n",
    "    for image in os.listdir(dir + 'data/Images/' + str(eid)):\n",
    "        if image.endswith('.jpg'):\n",
    "            item = {}\n",
    "            imid = os.path.splitext(image)[0] \n",
    "            item['exam id'] = eid\n",
    "            item['impath'] = eid + '/' + image\n",
    "            if '_' in image and os.path.exists(dir + 'data/Images/' + str(eid) + '/' + 'SSImages_BB' + '/' + 'ss_' + image):             \n",
    "                leg = imid.split('_')[-1]\n",
    "                \n",
    "                if leg != 'B':\n",
    "                    view = imid.split('_')[-2]\n",
    "\n",
    "                    item['imid'] = imid #.split('_')[0]\n",
    "                    item['leg'] = leg\n",
    "                    item['view'] = view\n",
    "                    if view not in views.keys():\n",
    "                        views[view] = 0\n",
    "                    views[view] = views[view] + 1\n",
    "\n",
    "                    f_ = open(dir + 'data/Images/' + str(eid) + '/' + 'SSImages_BB' + '/'  + image + '.txt', 'r')\n",
    "                    item['bbox'] = f_.readlines()[1].rstrip('\\n').split(' ')\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "            sample_images.append(item)\n",
    "print views\n",
    "print len(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/medic02/users/ag6516/miniconda/envs/TensorFlow/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train, test = model_selection.train_test_split(sample_images, train_size=0.8, random_state=42)\n",
    "\n",
    "print len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crop and pad images, adjust bounding box coordinates\n",
    "\n",
    "def crop_image(im, bbox):\n",
    "    # Central crop to 256x256\n",
    "    im = np.array(im)\n",
    "    h, w, _ = im.shape\n",
    "    #print 'Before: ',h,w\n",
    "    if h > 256 and w > 256:\n",
    "        im = im[h//2-128:h//2+128, w//2-128:w//2+128]\n",
    "        bbox[0] = bbox[0] - (w-256)//2\n",
    "        bbox[1] = bbox[1] - (h-256)//2\n",
    "        bbox[2] = bbox[2] - (w-256)//2\n",
    "        bbox[3] = bbox[3] - (h-256)//2\n",
    "    elif h > 256 and w < 256:\n",
    "        #print 'width<256 ', p\n",
    "        p = abs(w-256)//2\n",
    "        im = im[h//2-128:h//2+128, :]\n",
    "        if abs(w-256)%2==0:\n",
    "            im = np.pad(im, ((0,0), (p,p), (0,0)), 'maximum')\n",
    "        else:\n",
    "            im = np.pad(im, ((0,0), (p,p+1), (0,0)), 'maximum')\n",
    "        bbox[0] = bbox[0] + p\n",
    "        bbox[1] = bbox[1] - (h-256)//2\n",
    "        bbox[2] = bbox[2] + p\n",
    "        bbox[3] = bbox[3] - (h-256)//2\n",
    "    elif h < 256 and w > 256:\n",
    "        p = abs(h-256)//2\n",
    "        #print 'height<256 ', p\n",
    "        im = im[:,  w//2-128:w//2+128]\n",
    "        if abs(h-256)%2==0:\n",
    "            im = np.pad(im, ((p,p), (0,0), (0,0)), 'maximum')\n",
    "        else:\n",
    "            im = np.pad(im, ((p,p+1), (0,0), (0,0)), 'maximum')\n",
    "        bbox[0] = bbox[0] - (w-256)//2\n",
    "        bbox[1] = bbox[1] + p\n",
    "        bbox[2] = bbox[2] - (w-256)//2\n",
    "        bbox[3] = bbox[3] + p\n",
    "    elif h < 256 and w < 256:\n",
    "        ph = abs(h-256)//2\n",
    "        pw = abs(w-256)//2\n",
    "        print pw, ph\n",
    "        im = np.pad(im, ((ph,ph), (pw,pw), (0,0)), 'maximum')\n",
    "        bbox[0] = bbox[0] + pw\n",
    "        bbox[1] = bbox[1] + ph\n",
    "        bbox[2] = bbox[2] + pw\n",
    "        bbox[3] = bbox[3] + ph\n",
    "    \n",
    "    # if bounding boxes fall out of range, set to max height/width\n",
    "    if bbox[0] < 0:\n",
    "        bbox[0] = 0\n",
    "    if bbox[1] < 0:\n",
    "        bbox[1] = 0\n",
    "    if bbox[2] > 256:\n",
    "        bbox[2] = 256\n",
    "    if bbox[3] > 256:\n",
    "        bbox[3] = 256\n",
    "    #rawim = np.copy(im).astype('uint8')\n",
    "    h, w, _ = im.shape\n",
    "    #print 'After: ', h,w\n",
    "    return im, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_batch(data, batch_size=100, display_images = False):\n",
    "    batch = random.sample(data, batch_size)\n",
    "    images = []\n",
    "    bboxes = []\n",
    "    for i in batch:\n",
    "        if display_images:\n",
    "            plt.figure()\n",
    "        \n",
    "        path = dir + 'data/Images/' + str(i['exam id']) + '/' + 'SSImages_BB' + '/'  + 'ss_' + i['imid'] + '.jpg'\n",
    "        im = plt.imread(path)\n",
    "        bbox = np.asarray(i['bbox'], dtype=int)\n",
    "        if display_images:\n",
    "        #print 'Original: ', im.shape, 'Original bbox: ', i['bbox']\n",
    "            plt.subplot(1,2,1).set_title('Org. bbox: ' + str(bbox))\n",
    "            plt.subplot(1,2,1).imshow(im)\n",
    "            rect1 = patches.Rectangle((bbox[0],bbox[1]),abs(bbox[2]-bbox[0]),abs(bbox[3]-bbox[1]),linewidth=1,edgecolor='r',facecolor='none')\n",
    "            plt.subplot(1,2,1).add_patch(rect1)\n",
    "        \n",
    "        im, bbox = crop_image(im, bbox)\n",
    "        if display_images:\n",
    "        #print 'Cropped: ', im.shape, 'Adjusted bbox: ', bbox\n",
    "            plt.subplot(1,2,2).set_title('Adj. bbox: ' + str(bbox))\n",
    "            plt.subplot(1,2,2).imshow(im)\n",
    "            rect2 = patches.Rectangle((bbox[0],bbox[1]),abs(bbox[2]-bbox[0]),abs(bbox[3]-bbox[1]),linewidth=1,edgecolor='r',facecolor='none')\n",
    "            plt.subplot(1,2,2).add_patch(rect2)\n",
    "        \n",
    "        images.append(im)\n",
    "        bboxes.append(bbox)\n",
    "\n",
    "    return np.array(images), np.array(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "images, bboxes = next_batch(train, batch_size=184)\n",
    "print images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 256*256*3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "\n",
    "W = tf.Variable(tf.zeros([256*256*3,4]))\n",
    "b = tf.Variable(tf.zeros([4]))\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "y = tf.matmul(x,W) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.losses.cosine_distance(y_, y, dim=1))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.32256e+15\n",
      "-1.14376e+15\n",
      "-1.52971e+15\n",
      "-1.43197e+15\n",
      "-2.02032e+15\n",
      "-1.83512e+15\n",
      "-1.89852e+15\n",
      "-2.26333e+15\n",
      "-2.1483e+15\n",
      "-2.28611e+15\n"
     ]
    }
   ],
   "source": [
    "BS = 20\n",
    "print_y = tf.Print(y,[y])\n",
    "\n",
    "for i in range(1000):\n",
    "    images, bboxes = next_batch(train, batch_size=20)\n",
    "    images = np.reshape(images, [BS, 256*256*3])\n",
    "    train_step.run(feed_dict={x: images, y_: bboxes})\n",
    "    if i%100==0:\n",
    "        print loss.eval(feed_dict={x: images, y_: bboxes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "# Input Layer\n",
    "input_layer = tf.placeholder(tf.float32, [None, 256, 256, 3])\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=32,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# Pooling Layer #1\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Convolutional Layer #2 and Pooling Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# Dense Layer\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(\n",
    "    inputs=dense, rate=0.4, training=tf.estimator.ModeKeys.TRAIN == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "# Output Layer\n",
    "output = tf.layers.dense(inputs=dropout, units=4)\n",
    "\n",
    "# Loss\n",
    "loss = tf.reduce_mean(tf.losses.cosine_distance(bboxes, output))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "      for i in range(20000):\n",
    "        images, bboxes = next_batch(train, batch_size=10)\n",
    "        if i % 100 == 0:\n",
    "            train_loss = loss.eval(feed_dict={\n",
    "                x: images, y_: bboxes})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlow]",
   "language": "python",
   "name": "conda-env-TensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
