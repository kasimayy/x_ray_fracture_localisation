{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set local python and nltk paths\n",
    "import sys\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TensorFlowCPU/lib/python2.7/site-packages')\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TensorFlowCPU/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg')\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TensorFlowCPU/lib/python2.7/site-packages/IPython/extensions')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "from random import randint\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir = ('/vol/medic02/users/ag6516/x_ray_fracture_localisation/')\n",
    "# dir = ('/Users/Aydan/PhD/x_ray_fracture_localisation/')\n",
    "df = pd.read_csv(dir + 'cleaned_reports_edited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_ids = []\n",
    "for folder in os.listdir(dir+'data/Images'):\n",
    "    exam_ids.append(str(folder))\n",
    "    \n",
    "print len(exam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = []\n",
    "views = {}\n",
    "for eid in exam_ids:\n",
    "    for image in os.listdir(dir + 'data/Images/' + str(eid)):\n",
    "        if image.endswith('.jpg'):\n",
    "            item = {}\n",
    "            imid = os.path.splitext(image)[0] \n",
    "            item['exam id'] = eid\n",
    "            item['impath'] = eid + '/' + image\n",
    "            if '_' in image and os.path.exists(dir + 'data/Images/' + str(eid) + '/' + 'SSImages_BB' + '/' + 'ss_' + image):             \n",
    "                leg = imid.split('_')[-1]\n",
    "                \n",
    "                if leg != 'B':\n",
    "                    view = imid.split('_')[-2]\n",
    "\n",
    "                    item['imid'] = imid #.split('_')[0]\n",
    "                    item['leg'] = leg\n",
    "                    item['view'] = view\n",
    "                    if view not in views.keys():\n",
    "                        views[view] = 0\n",
    "                    views[view] = views[view] + 1\n",
    "\n",
    "                    f_ = open(dir + 'data/Images/' + str(eid) + '/' + 'SSImages_BB' + '/'  + image + '.txt', 'r')\n",
    "                    item['bbox'] = f_.readlines()[1].rstrip('\\n').split(' ')\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "            sample_images.append(item)\n",
    "print views\n",
    "print len(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(sample_images, train_size=0.8, random_state=42)\n",
    "\n",
    "print len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crop and pad images, downsample, adjust bounding box coordinates\n",
    "\n",
    "def crop_image(im, bbox, ds=1):\n",
    "    # Central crop to 224x224\n",
    "    im = np.array(im)\n",
    "    h, w, _ = im.shape\n",
    "    #print 'Before: ',h,w\n",
    "    if h > 256 and w > 256:\n",
    "        im = im[h//2-128:h//2+128, w//2-128:w//2+128]\n",
    "        bbox[0] = bbox[0] - (w-256)//2\n",
    "        bbox[1] = bbox[1] - (h-256)//2\n",
    "        bbox[2] = bbox[2] - (w-256)//2\n",
    "        bbox[3] = bbox[3] - (h-256)//2\n",
    "    elif h > 256 and w < 256:\n",
    "        #print 'width<256 ', p\n",
    "        p = abs(w-256)//2\n",
    "        im = im[h//2-128:h//2+128, :]\n",
    "        if abs(w-256)%2==0:\n",
    "            im = np.pad(im, ((0,0), (p,p), (0,0)), 'maximum')\n",
    "        else:\n",
    "            im = np.pad(im, ((0,0), (p,p+1), (0,0)), 'maximum')\n",
    "        bbox[0] = bbox[0] + p\n",
    "        bbox[1] = bbox[1] - (h-256)//2\n",
    "        bbox[2] = bbox[2] + p\n",
    "        bbox[3] = bbox[3] - (h-256)//2\n",
    "    elif h < 256 and w > 256:\n",
    "        p = abs(h-256)//2\n",
    "        #print 'height<256 ', p\n",
    "        im = im[:,  w//2-128:w//2+128]\n",
    "        if abs(h-256)%2==0:\n",
    "            im = np.pad(im, ((p,p), (0,0), (0,0)), 'maximum')\n",
    "        else:\n",
    "            im = np.pad(im, ((p,p+1), (0,0), (0,0)), 'maximum')\n",
    "        bbox[0] = bbox[0] - (w-256)//2\n",
    "        bbox[1] = bbox[1] + p\n",
    "        bbox[2] = bbox[2] - (w-256)//2\n",
    "        bbox[3] = bbox[3] + p\n",
    "    elif h < 256 and w < 256:\n",
    "        ph = abs(h-256)//2\n",
    "        pw = abs(w-256)//2\n",
    "        print pw, ph\n",
    "        im = np.pad(im, ((ph,ph), (pw,pw), (0,0)), 'maximum')\n",
    "        bbox[0] = bbox[0] + pw\n",
    "        bbox[1] = bbox[1] + ph\n",
    "        bbox[2] = bbox[2] + pw\n",
    "        bbox[3] = bbox[3] + ph\n",
    "    \n",
    "    # if bounding boxes fall out of range, set to max height/width\n",
    "    if bbox[0] < 0:\n",
    "        bbox[0] = 0\n",
    "    if bbox[1] < 0:\n",
    "        bbox[1] = 0\n",
    "    if bbox[2] > 256:\n",
    "        bbox[2] = 256\n",
    "    if bbox[3] > 256:\n",
    "        bbox[3] = 256\n",
    "    #rawim = np.copy(im).astype('uint8')\n",
    "    h, w, _ = im.shape\n",
    "    #print 'After: ', h,w\n",
    "    return im, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(data, batch_size=100, display_images = False):\n",
    "    batch = random.sample(data, batch_size)\n",
    "    images = []\n",
    "    bboxes = []\n",
    "    for i in batch:\n",
    "        if display_images:\n",
    "            plt.figure()\n",
    "        \n",
    "        path = dir + 'data/Images/' + str(i['exam id']) + '/' + 'SSImages_BB' + '/'  + 'ss_' + i['imid'] + '.jpg'\n",
    "        im = plt.imread(path)\n",
    "        bbox = np.asarray(i['bbox'], dtype=int)\n",
    "        if display_images:\n",
    "        #print 'Original: ', im.shape, 'Original bbox: ', i['bbox']\n",
    "            plt.subplot(1,2,1).set_title('Org. bbox: ' + str(bbox))\n",
    "            plt.subplot(1,2,1).imshow(im)\n",
    "            rect1 = patches.Rectangle((bbox[0],bbox[1]),abs(bbox[2]-bbox[0]),abs(bbox[3]-bbox[1]),linewidth=1,edgecolor='r',facecolor='none')\n",
    "            plt.subplot(1,2,1).add_patch(rect1)\n",
    "        \n",
    "        im, bbox = crop_image(im, bbox)\n",
    "        if display_images:\n",
    "        #print 'Cropped: ', im.shape, 'Adjusted bbox: ', bbox\n",
    "            plt.subplot(1,2,2).set_title('Adj. bbox: ' + str(bbox))\n",
    "            plt.subplot(1,2,2).imshow(im)\n",
    "            rect2 = patches.Rectangle((bbox[0],bbox[1]),abs(bbox[2]-bbox[0]),abs(bbox[3]-bbox[1]),linewidth=1,edgecolor='r',facecolor='none')\n",
    "            plt.subplot(1,2,2).add_patch(rect2)\n",
    "        \n",
    "        images.append(im)\n",
    "        bboxes.append(bbox)\n",
    "        \n",
    "    return np.array(images), np.array(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, bboxes = next_batch(train, batch_size=184)\n",
    "print images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 256*256*3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "\n",
    "W = tf.Variable(tf.zeros([256*256*3,4]))\n",
    "b = tf.Variable(tf.zeros([4]))\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "y = tf.matmul(x,W) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.losses.mean_squared_error(y_, y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BS = 20\n",
    "print_y = tf.Print(y,[y])\n",
    "\n",
    "for i in range(1000):\n",
    "    images, bboxes = next_batch(train, batch_size=20)\n",
    "    images = np.reshape(images, [BS, 256*256*3])\n",
    "    train_step.run(feed_dict={x: images, y_: bboxes})\n",
    "    if i%100==0:\n",
    "        print loss.eval(feed_dict={x: images, y_: bboxes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_input  = 256*256*3\n",
    "n_output = 4\n",
    "\n",
    "def conv_simple(_input):\n",
    "    # Convolutional Layer #1\n",
    "    _conv1 = tf.layers.conv2d(\n",
    "        inputs=_input,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    _pool1 = tf.layers.max_pooling2d(inputs=_conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    _conv2 = tf.layers.conv2d(\n",
    "        inputs=_pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    _pool2 = tf.layers.max_pooling2d(inputs=_conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    _pool2_flat = tf.reshape(_pool2, [-1, 5242880])\n",
    "\n",
    "    #_pool1_flat = tf.reshape(_pool1, [-1, 524288])\n",
    "    \n",
    "    _dense = tf.layers.dense(inputs=_pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # Output Layer\n",
    "    _out = tf.layers.dense(inputs=_dense, units=4)\n",
    "    \n",
    "    # Return everything\n",
    "    out = {\n",
    "        'input': _input, 'conv1': _conv1, 'conv2': _conv2, \n",
    "        'pool1': _pool1,\n",
    "        'pool2': _pool2, \n",
    "        'dense': _dense, 'out': _out\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 256, 256, 3])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "\n",
    "# Parameters\n",
    "learning_rate   = 0.001\n",
    "training_epochs = 10\n",
    "batch_size      = 1\n",
    "display_step    = 1\n",
    "\n",
    "# Functions! \n",
    "\n",
    "_pred = conv_simple(x)['out']\n",
    "cost = tf.reduce_mean(tf.losses.mean_squared_error(_pred, y))\n",
    "optm = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#_corr = tf.equal(tf.argmax(_pred,1), tf.argmax(y,1)) # Count corrects\n",
    "#accr = tf.reduce_mean(tf.cast(_corr, tf.float32)) # Accuracy\n",
    "#init = tf.initialize_all_variables()\n",
    "\n",
    "# Saver \n",
    "save_step = 1;\n",
    "savedir = \"nets/\"\n",
    "saver = tf.train.Saver(max_to_keep=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "#sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(len(train)/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = next_batch(train, batch_size)\n",
    "            # Fit training using batch data\n",
    "            sess.run(optm, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0: \n",
    "            print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "            #train_acc = sess.run(accr, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            print (\" Training cost: %.3f\" % (avg_cost))\n",
    "            testimgs, testbboxs = next_batch(test, batch_size=47)\n",
    "            test_cost = sess.run(cost, feed_dict={x: testimgs, y: testbboxs})\n",
    "            print (\" Test cost: %.3f\" % (test_acc))\n",
    "\n",
    "        # Save Net\n",
    "        if epoch % save_step == 0:\n",
    "            saver.save(sess, \"nets/cnn_bboxes_simple.ckpt-\" + str(epoch))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlowCPU]",
   "language": "python",
   "name": "conda-env-TensorFlowCPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
