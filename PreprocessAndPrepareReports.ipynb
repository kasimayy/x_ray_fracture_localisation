{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set local python and nltk paths\n",
    "import sys\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages')\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg')\n",
    "sys.path.insert(0,'/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages/IPython/extensions')\n",
    "sys.path\n",
    "import nltk\n",
    "nltk.data.path = ['/vol/medic02/users/ag6516/nltk_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 164, in <module>\n",
      "    use(config.device)\n",
      "  File \"/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 151, in use\n",
      "    init_dev(device)\n",
      "  File \"/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 66, in init_dev\n",
      "    avail = dnn.dnn_available(name)\n",
      "  File \"/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages/theano/gpuarray/dnn.py\", line 174, in dnn_available\n",
      "    if not dnn_present():\n",
      "  File \"/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages/theano/gpuarray/dnn.py\", line 157, in dnn_present\n",
      "    dnn_present.avail, dnn_present.msg = _dnn_check_version()\n",
      "  File \"/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages/theano/gpuarray/dnn.py\", line 130, in _dnn_check_version\n",
      "    v = version()\n",
      "  File \"/vol/medic02/users/ag6516/miniconda/envs/TheanoLasagne/lib/python2.7/site-packages/theano/gpuarray/dnn.py\", line 342, in version\n",
      "    \"while the library is version %s.\" % v)\n",
      "RuntimeError: Mixed dnn version. The header is version 5110 while the library is version 6021.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import randint\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set THEANO_FLAGS='device=cuda0,floatX=float32' to run notebook on gpu\n",
    "import lasagne\n",
    "from lasagne.utils import floatX\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from collections import Counter\n",
    "from lasagne.utils import floatX\n",
    "\n",
    "import googlenet\n",
    "\n",
    "from read_data import read_csv_into_df\n",
    "from vis_utils import kmeans_clustering, plot_pca, visualise_word_clusters2, kmeans_silhouette\n",
    "from vis_utils import save_clusters_to_json, load_clusters_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir = ('/vol/medic02/users/ag6516/x_ray_fracture_localisation/')\n",
    "# dir = ('/Users/Aydan/PhD/x_ray_fracture_localisation/')\n",
    "df = pd.read_csv(dir + 'cleaned_reports_edited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reports = []\n",
    "reports_tok = []\n",
    "labels = []\n",
    "words = []\n",
    "report_lengths = []\n",
    "num_sentences = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    report = row['Report text'].decode('utf-8').lower()\n",
    "    num_sentences.append(report.count('.'))\n",
    "    # Remove markdown\n",
    "    for char in ['\\n', '\\b']:\n",
    "        report = report.replace(char, '')\n",
    "    \n",
    "    # Replace unnecessary punctuation \n",
    "    for char in ['~', '\"']:\n",
    "        report = report.replace(char, '')\n",
    "        \n",
    "    for char in ['!', '?', ';', ':', '.']:\n",
    "        report = report.replace(char, ' . ')\n",
    "    \n",
    "    for char in ['(', ')', ',', '/', '\\\\']:\n",
    "        report = report.replace(char, ' , ')\n",
    "        \n",
    "    # filter out 'comparison' + dates\n",
    "    #report = re.sub('( compar.*?\\d{4})', '', report)\n",
    "    report = re.sub('(compar.*?\\d{4})', '', report)\n",
    "    report = re.sub('(compar.*?\\d{2})', '', report)\n",
    "    report = re.sub('(xr knee both)', '', report)\n",
    "    report = re.sub('(xr knee)', '', report)\n",
    "    report = re.sub('(previous.*comparison)', '', report)\n",
    "    report = re.sub('( please.*?\\.)', '', report)\n",
    "\n",
    "    # Tokenize\n",
    "    report_tok = word_tokenize(report)\n",
    "    report_length = len(report_tok)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    filtered_report_tok = [word for word in report_tok if word not in stopwords.words('english')]\n",
    "    filtered_report = ' '.join(filtered_report_tok)\n",
    "    \n",
    "    reports.append(filtered_report)\n",
    "    reports_tok.append(filtered_report_tok)\n",
    "    labels.append(row['Accession'])\n",
    "    [words.append(word) for word in filtered_report_tok]\n",
    "    report_lengths.append(report_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length:  1735\n",
      "Avg no. of appearances:  35.4039238315\n",
      "Max:  [(u'.', 12474), (u'joint', 3749)]\n",
      "STD:  170.997692276\n",
      "Number of reports:  3561\n",
      "Average length of report:  30.5237292895\n",
      "STD:  18.2751155872\n",
      "\n",
      "Average number of sentences:  2.70176916596\n",
      "STD:  1.96696094788\n",
      "\n",
      "Unnamed: 0          3561\n",
      "Accession           3561\n",
      "Clinical history    2221\n",
      "Comment             2390\n",
      "Report text         3561\n",
      "Cleaned report      3561\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print 'Vocab length: ', len(sorted(set(words)))\n",
    "fdist_all = nltk.FreqDist(words)\n",
    "freqs = [freq for word, freq in fdist_all.most_common() if word not in ['.', ',']]\n",
    "print 'Avg no. of appearances: ', np.mean(freqs)\n",
    "print 'Max: ', fdist_all.most_common(2)\n",
    "print 'STD: ', np.std(freqs)\n",
    "#print fdist_all.hapaxes()\n",
    "print 'Number of reports: ', len(reports)\n",
    "print 'Average length of report: ', np.mean(report_lengths)\n",
    "print 'STD: ', np.std(report_lengths)\n",
    "print ''\n",
    "print 'Average number of sentences: ', np.mean(num_sentences)\n",
    "print 'STD: ', np.std(num_sentences)\n",
    "print ''\n",
    "df['Cleaned report'] = reports\n",
    "print df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patient_ids = []\n",
    "for folder in os.listdir(dir+'data/Images'):\n",
    "    #os.path.exists(self.labelfilename)\n",
    "    patient_ids.append(str(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n"
     ]
    }
   ],
   "source": [
    "print len(patient_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HBL': 12, 'WBAP': 34, 'L': 90, 'AP': 69, 'S': 33, 'WBL': 17}\n"
     ]
    }
   ],
   "source": [
    "sample_images = []\n",
    "views = {}\n",
    "for pid in patient_ids:\n",
    "    for image in os.listdir(dir + 'data/Images/' + str(pid)):\n",
    "        if image.endswith('.jpg'):\n",
    "            item = {}\n",
    "            imid = os.path.splitext(image)[0] \n",
    "            item['patient id'] = pid\n",
    "            item['impath'] = pid + '/' + image\n",
    "            if pid in labels:\n",
    "                item['report'] = reports[labels.index(pid)]\n",
    "                item['tokens'] = reports_tok[labels.index(pid)]\n",
    "                if '_' in image:             \n",
    "                    leg = imid.split('_')[-1]\n",
    "                    view = imid.split('_')[-2]\n",
    "                \n",
    "                    item['imid'] = imid.split('_')[0]\n",
    "                    item['leg'] = leg\n",
    "                    item['view'] = view\n",
    "                    if view not in views.keys():\n",
    "                        views[view] = 0\n",
    "                    views[view] = views[view] + 1\n",
    "                else:\n",
    "                    item['imid'] = imid\n",
    "            else: continue\n",
    "\n",
    "            sample_images.append(item)\n",
    "print views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allwords = Counter()\n",
    "pids = set()\n",
    "for item in sample_images:\n",
    "    pid = item['patient id']\n",
    "    if pid not in pids:\n",
    "        tokens = item['tokens']\n",
    "        allwords.update(tokens)\n",
    "\n",
    "    pids.add(pid) \n",
    "\n",
    "vocab = [k for k, v in allwords.items() if v >= 10]\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in sample_images:\n",
    "    old_tokens = item['tokens']\n",
    "    item['tokens'] = [word for word in old_tokens if word in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1, test = model_selection.train_test_split(sample_images, train_size=0.8, random_state=42)\n",
    "train, val = model_selection.train_test_split(train1, train_size=0.8, random_state=42)\n",
    "\n",
    "for item in train:\n",
    "    item['split'] = 'train'\n",
    "\n",
    "for item in val:\n",
    "    item['split'] = 'val'\n",
    "\n",
    "for item in test:\n",
    "    item['split'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  916\n",
      "Val:  229\n",
      "Test:  287\n",
      "Total 1432\n"
     ]
    }
   ],
   "source": [
    "sample_images = train+test+val\n",
    "print 'Train: ', len(train)\n",
    "print 'Val: ', len(val)\n",
    "print 'Test: ', len(test)\n",
    "print 'Total', len(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(sample_images, open('sample_exams_train_test_split.pkl','w'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TheanoLasagne]",
   "language": "python",
   "name": "conda-env-TheanoLasagne-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
